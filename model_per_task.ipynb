{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file into variable \"data\"\n",
    "with open('data_entries_ti_uniform.json', 'r', encoding='UTF-8') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import customer feature engineering functions\n",
    "from feature_engineering_functions import calculate_time_differences, calculate_distances, calculate_edge_types, calculate_speeds, calculate_directions, calculate_pressure_diffs, calculate_fraction_pen_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas dataframe from the JSON file: simpler exploring, feature engineering, and filtering with a dataframe. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(columns=[\"participant\", \"task\", \"label\", \"x_coords\", \"y_coords\", \n",
    "                           \"pressure\", \"times\", \"distances\", \"edgetypes\", \n",
    "                           \"speeds\", \"directions\", \"pressure_diffs\", \"fractions\"])\n",
    "\n",
    "for entry in data:\n",
    "    participant_id = entry[\"participant\"]\n",
    "    task = entry[\"task\"]\n",
    "    class_label = 0 if participant_id.startswith(\"H\") else 1\n",
    "\n",
    "    # Filter data for nodes where pressure > 0 and get their original indices\n",
    "    indices = [i for i, row in enumerate(entry[\"data\"]) if row[2] > 0]\n",
    "    filtered_data = [entry[\"data\"][i] for i in indices]\n",
    "\n",
    "    # Extract Node features\n",
    "    x_coords = [row[0] for row in filtered_data]\n",
    "    y_coords = [row[1] for row in filtered_data]\n",
    "    pressure = [row[2] for row in filtered_data]\n",
    "\n",
    "    # Extract engineered Edge features\n",
    "    times = calculate_time_differences(entry[\"data\"])\n",
    "    distances = calculate_distances(x_coords, y_coords)\n",
    "    edgetypes = calculate_edge_types(entry[\"data\"])\n",
    "    speeds = calculate_speeds(distances, times)\n",
    "    directions = calculate_directions(x_coords, y_coords)\n",
    "    pressure_diffs = calculate_pressure_diffs(pressure)\n",
    "    fractions = calculate_fraction_pen_on(indices)\n",
    "\n",
    "    # Add row to dataframe\n",
    "    df.loc[len(df)] = [participant_id, task, class_label, x_coords, y_coords, \n",
    "                       pressure, times, distances, edgetypes, speeds, \n",
    "                       directions, pressure_diffs, fractions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out missing data\n",
    "df_filtered = df[(df[\"x_coords\"].apply(len) > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tasks: 25\n"
     ]
    }
   ],
   "source": [
    "# Get unique tasks\n",
    "tasks = df_filtered['task'].unique()\n",
    "# Group tasks where each task is a key, and the corresponding rows (as a DataFrame) where task matches are stored as values. \n",
    "task_dfs = {task: df_filtered[df_filtered['task'] == task] for task in tasks}\n",
    "print(f\"Number of tasks: {len(tasks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task T15: Train size: 117, Val size: 26, Test size: 26\n",
      "Task T16: Train size: 118, Val size: 26, Test size: 26\n",
      "Task T17: Train size: 118, Val size: 26, Test size: 26\n",
      "Task T18: Train size: 118, Val size: 26, Test size: 26\n",
      "Task T19: Train size: 97, Val size: 21, Test size: 21\n",
      "Task T20: Train size: 114, Val size: 25, Test size: 25\n",
      "Task T21: Train size: 111, Val size: 25, Test size: 24\n",
      "Task T22: Train size: 114, Val size: 25, Test size: 25\n",
      "Task T23: Train size: 115, Val size: 25, Test size: 25\n",
      "Task T24: Train size: 113, Val size: 25, Test size: 25\n",
      "Task T25: Train size: 111, Val size: 25, Test size: 25\n",
      "Task T1: Train size: 120, Val size: 26, Test size: 26\n",
      "Task T2: Train size: 119, Val size: 26, Test size: 26\n",
      "Task T3: Train size: 120, Val size: 26, Test size: 26\n",
      "Task T4: Train size: 121, Val size: 26, Test size: 26\n",
      "Task T10: Train size: 118, Val size: 26, Test size: 26\n",
      "Task T11: Train size: 118, Val size: 26, Test size: 26\n",
      "Task T12: Train size: 117, Val size: 26, Test size: 26\n",
      "Task T13: Train size: 116, Val size: 26, Test size: 26\n",
      "Task T14: Train size: 116, Val size: 25, Test size: 25\n",
      "Task T5: Train size: 118, Val size: 26, Test size: 26\n",
      "Task T6: Train size: 119, Val size: 26, Test size: 26\n",
      "Task T7: Train size: 120, Val size: 26, Test size: 26\n",
      "Task T8: Train size: 118, Val size: 26, Test size: 26\n",
      "Task T9: Train size: 118, Val size: 26, Test size: 26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "task_splits = {}\n",
    "for task, task_df in task_dfs.items():\n",
    "    train_val_df, test_df = train_test_split(task_df, test_size=0.15, random_state=5)\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=0.1765, random_state=5)  # 0.1765 * 0.85 â‰ˆ 0.15\n",
    "    task_splits[task] = {'train': train_df, 'val': val_df, 'test': test_df}\n",
    "    print(f\"Task {task}: Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness_corrections(train_df, val_df, test_df):\n",
    "    import numpy as np\n",
    "    from scipy.special import logit\n",
    "    def flatten_column(df, column):\n",
    "        return np.concatenate(df[column].values) if not df[column].empty else np.array([])\n",
    "\n",
    "    # Fit parameters on training set\n",
    "    pressure_train = flatten_column(train_df, 'pressure')\n",
    "    max_pressure = np.max(pressure_train) if len(pressure_train) > 0 else 2047\n",
    "    pressure_diffs_train = flatten_column(train_df, 'pressure_diffs')\n",
    "    min_pressure_diffs = np.min(pressure_diffs_train) if len(pressure_diffs_train) > 0 else -1315\n",
    "\n",
    "    # Transform function\n",
    "    def transform_df(df):\n",
    "        df_transformed = df.copy()\n",
    "        \n",
    "        # No transformation for mild skewness\n",
    "        df_transformed['x_coords_transformed'] = df['x_coords']\n",
    "        df_transformed['y_coords_transformed'] = df['y_coords']\n",
    "        df_transformed['directions_transformed'] = df['directions']\n",
    "        \n",
    "        # Log for positive skewness with small constant to avoid log(0)\n",
    "        df_transformed['times_transformed'] = df['times'].apply(\n",
    "            lambda x: np.log(np.array(x) + 1e-6) if len(x) > 0 else x\n",
    "        )\n",
    "        df_transformed['distances_transformed'] = df['distances'].apply(\n",
    "            lambda x: np.log(np.array(x) + 1e-6) if len(x) > 0 else x\n",
    "        )\n",
    "        df_transformed['speeds_transformed'] = df['speeds'].apply(\n",
    "            lambda x: np.log(np.array(x) + 1e-6) if len(x) > 0 else x\n",
    "        )\n",
    "        \n",
    "        # Reflect and log for negative skewness\n",
    "        df_transformed['pressure_transformed'] = df['pressure'].apply(\n",
    "            lambda x: np.log(max_pressure - np.array(x) + 1) if len(x) > 0 else x\n",
    "        )\n",
    "        df_transformed['pressure_diffs_transformed'] = df['pressure_diffs'].apply(\n",
    "            lambda x: np.log(np.maximum(np.array(x) - min_pressure_diffs + 1, 1e-6)) if len(x) > 0 else x\n",
    "        )\n",
    "        \n",
    "        # Logit for fractions\n",
    "        df_transformed['fractions_transformed'] = df['fractions'].apply(\n",
    "            lambda x: logit(np.clip(np.array(x), 0.01, 0.99)) if len(x) > 0 else x\n",
    "        )\n",
    "        \n",
    "        # No change for edgetypes (binary values)\n",
    "        df_transformed['edgetypes_transformed'] = df['edgetypes']\n",
    "        \n",
    "        return df_transformed\n",
    "\n",
    "    # Apply to all sets\n",
    "    train_df_transformed = transform_df(train_df)\n",
    "    val_df_transformed = transform_df(val_df)\n",
    "    test_df_transformed = transform_df(test_df)\n",
    "    \n",
    "    return train_df_transformed, val_df_transformed, test_df_transformed\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def apply_scaling_after_transform(train_df, val_df, test_df):\n",
    "    # Initialize scalers\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    standard_scaler = StandardScaler()\n",
    "\n",
    "    # Columns to scale\n",
    "    norm_cols = ['x_coords_transformed', 'y_coords_transformed']\n",
    "    std_cols = ['pressure_transformed', 'times_transformed', 'distances_transformed', \n",
    "                'speeds_transformed', 'pressure_diffs_transformed', 'fractions_transformed']\n",
    "    no_scale_cols = ['edgetypes_transformed', 'directions_transformed']\n",
    "\n",
    "    # Fit scalers on training data\n",
    "    for col in norm_cols:\n",
    "        train_flat = np.concatenate(train_df[col].values)\n",
    "        train_flat = np.clip(train_flat, -1e10, 1e10)\n",
    "        train_flat = np.nan_to_num(train_flat, nan=0.0, posinf=1e10, neginf=-1e10)\n",
    "        minmax_scaler.fit(train_flat.reshape(-1, 1))\n",
    "        for df in [train_df, val_df, test_df]:\n",
    "            df[f'{col}_scaled'] = df[col].apply(\n",
    "                lambda x: minmax_scaler.transform(\n",
    "                    np.clip(np.nan_to_num(x, nan=0.0, posinf=1e10, neginf=-1e10), -1e10, 1e10).reshape(-1, 1)\n",
    "                ).flatten() if len(x) > 0 else x\n",
    "            )\n",
    "\n",
    "    for col in std_cols:\n",
    "        train_flat = np.concatenate(train_df[col].values)\n",
    "        train_flat = np.clip(train_flat, -1e10, 1e10)\n",
    "        train_flat = np.nan_to_num(train_flat, nan=0.0, posinf=1e10, neginf=-1e10)\n",
    "        standard_scaler.fit(train_flat.reshape(-1, 1))\n",
    "        for df in [train_df, val_df, test_df]:\n",
    "            df[f'{col}_scaled'] = df[col].apply(\n",
    "                lambda x: standard_scaler.transform(\n",
    "                    np.clip(np.nan_to_num(x, nan=0.0, posinf=1e10, neginf=-1e10), -1e10, 1e10).reshape(-1, 1)\n",
    "                ).flatten() if len(x) > 0 else x\n",
    "            )\n",
    "\n",
    "    # Copy unscaled columns\n",
    "    for col in no_scale_cols:\n",
    "        for df in [train_df, val_df, test_df]:\n",
    "            df[f'{col}_scaled'] = df[col]\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_processed = {}\n",
    "for task, splits in task_splits.items():\n",
    "    # Apply skewness corrections\n",
    "    train_df, val_df, test_df = skewness_corrections(splits['train'], splits['val'], splits['test'])\n",
    "    # Apply scaling\n",
    "    train_df, val_df, test_df = apply_scaling_after_transform(train_df, val_df, test_df)\n",
    "    task_processed[task] = {'train': train_df, 'val': val_df, 'test': test_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def create_data_list(df):\n",
    "    data_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        x = np.array(list(zip(\n",
    "            row['x_coords_transformed_scaled'],\n",
    "            row['y_coords_transformed_scaled'],\n",
    "            row['pressure_transformed_scaled']\n",
    "        )))\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        num_nodes = len(row['x_coords_transformed_scaled'])\n",
    "\n",
    "        if num_nodes > 1:\n",
    "            edge_attr = np.array(list(zip(\n",
    "                row['times_transformed_scaled'],\n",
    "                row['distances_transformed_scaled'],\n",
    "                row['edgetypes_transformed_scaled'],\n",
    "                row['speeds_transformed_scaled'],\n",
    "                row['directions_transformed_scaled'],\n",
    "                row['pressure_diffs_transformed_scaled'],\n",
    "                row['fractions_transformed_scaled']\n",
    "            )))\n",
    "\n",
    "            # Sanity Check:\n",
    "            expected_edges = num_nodes - 1\n",
    "            if edge_attr.shape[0] != expected_edges:\n",
    "                print(f\"Warning: Graph with {num_nodes} nodes has {edge_attr.shape[0]} edges, expected {expected_edges}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "            edge_index = torch.tensor([[i, i + 1] for i in range(num_nodes - 1)], dtype=torch.long).t()\n",
    "        else:\n",
    "            edge_attr = torch.empty((0, 7), dtype=torch.float)\n",
    "            edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "        y = torch.tensor([row['label']], dtype=torch.float)\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "        data_list.append(data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task T15: Train graphs: 117, Val graphs: 26, Test graphs: 26\n",
      "Task T16: Train graphs: 118, Val graphs: 26, Test graphs: 26\n",
      "Task T17: Train graphs: 118, Val graphs: 26, Test graphs: 26\n",
      "Task T18: Train graphs: 118, Val graphs: 26, Test graphs: 26\n",
      "Task T19: Train graphs: 97, Val graphs: 21, Test graphs: 21\n",
      "Task T20: Train graphs: 114, Val graphs: 25, Test graphs: 25\n",
      "Task T21: Train graphs: 111, Val graphs: 25, Test graphs: 24\n",
      "Task T22: Train graphs: 114, Val graphs: 25, Test graphs: 25\n",
      "Task T23: Train graphs: 115, Val graphs: 25, Test graphs: 25\n",
      "Task T24: Train graphs: 113, Val graphs: 25, Test graphs: 25\n",
      "Task T25: Train graphs: 111, Val graphs: 25, Test graphs: 25\n",
      "Task T1: Train graphs: 120, Val graphs: 26, Test graphs: 26\n",
      "Task T2: Train graphs: 119, Val graphs: 26, Test graphs: 26\n",
      "Task T3: Train graphs: 120, Val graphs: 26, Test graphs: 26\n",
      "Task T4: Train graphs: 121, Val graphs: 26, Test graphs: 26\n",
      "Task T10: Train graphs: 118, Val graphs: 26, Test graphs: 26\n",
      "Task T11: Train graphs: 118, Val graphs: 26, Test graphs: 26\n",
      "Task T12: Train graphs: 117, Val graphs: 26, Test graphs: 26\n",
      "Task T13: Train graphs: 116, Val graphs: 26, Test graphs: 26\n",
      "Task T14: Train graphs: 116, Val graphs: 25, Test graphs: 25\n",
      "Task T5: Train graphs: 118, Val graphs: 26, Test graphs: 26\n",
      "Task T6: Train graphs: 119, Val graphs: 26, Test graphs: 26\n",
      "Task T7: Train graphs: 120, Val graphs: 26, Test graphs: 26\n",
      "Task T8: Train graphs: 118, Val graphs: 26, Test graphs: 26\n",
      "Task T9: Train graphs: 118, Val graphs: 26, Test graphs: 26\n"
     ]
    }
   ],
   "source": [
    "task_graphs = {}\n",
    "for task, processed in task_processed.items():\n",
    "    graph_list_train = create_data_list(processed['train'])\n",
    "    graph_list_val = create_data_list(processed['val'])\n",
    "    graph_list_test = create_data_list(processed['test'])\n",
    "    task_graphs[task] = {'train': graph_list_train, 'val': graph_list_val, 'test': graph_list_test}\n",
    "    print(f\"Task {task}: Train graphs: {len(graph_list_train)}, Val graphs: {len(graph_list_val)}, Test graphs: {len(graph_list_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for Task T15\n",
      "Task: T15, Epoch: 001, Train Loss: 0.6982, Val Loss: 0.6731, Val Acc: 0.7692\n",
      "Task: T15, Epoch: 002, Train Loss: 0.6841, Val Loss: 0.6418, Val Acc: 0.7692\n",
      "Task: T15, Epoch: 003, Train Loss: 0.6806, Val Loss: 0.6177, Val Acc: 0.7308\n",
      "Task: T15, Epoch: 004, Train Loss: 0.6616, Val Loss: 0.6060, Val Acc: 0.6154\n",
      "Task: T15, Epoch: 005, Train Loss: 0.6742, Val Loss: 0.5703, Val Acc: 0.7692\n",
      "Task: T15, Epoch: 006, Train Loss: 0.6503, Val Loss: 0.5721, Val Acc: 0.6923\n",
      "Task: T15, Epoch: 007, Train Loss: 0.6504, Val Loss: 0.5345, Val Acc: 0.8462\n",
      "Task: T15, Epoch: 008, Train Loss: 0.6572, Val Loss: 0.4889, Val Acc: 0.8077\n",
      "Task: T15, Epoch: 009, Train Loss: 0.6326, Val Loss: 0.5574, Val Acc: 0.7308\n",
      "Task: T15, Epoch: 010, Train Loss: 0.6366, Val Loss: 0.5152, Val Acc: 0.9231\n",
      "Task: T15, Epoch: 011, Train Loss: 0.6144, Val Loss: 0.4449, Val Acc: 0.9231\n",
      "Task: T15, Epoch: 012, Train Loss: 0.6200, Val Loss: 0.4263, Val Acc: 0.8462\n",
      "Task: T15, Epoch: 013, Train Loss: 0.6013, Val Loss: 0.4296, Val Acc: 0.8462\n",
      "Task: T15, Epoch: 014, Train Loss: 0.5904, Val Loss: 0.4044, Val Acc: 0.9231\n",
      "Task: T15, Epoch: 015, Train Loss: 0.5932, Val Loss: 0.3860, Val Acc: 0.8846\n",
      "Task: T15, Epoch: 016, Train Loss: 0.6030, Val Loss: 0.4105, Val Acc: 0.8462\n",
      "Task: T15, Epoch: 017, Train Loss: 0.5858, Val Loss: 0.3774, Val Acc: 0.9231\n",
      "Task: T15, Epoch: 018, Train Loss: 0.5858, Val Loss: 0.4079, Val Acc: 0.8846\n",
      "Task: T15, Epoch: 019, Train Loss: 0.6040, Val Loss: 0.3757, Val Acc: 0.8462\n",
      "Task: T15, Epoch: 020, Train Loss: 0.5723, Val Loss: 0.3439, Val Acc: 0.9231\n",
      "Task: T15, Epoch: 021, Train Loss: 0.5754, Val Loss: 0.3608, Val Acc: 0.9231\n",
      "Task: T15, Epoch: 022, Train Loss: 0.5702, Val Loss: 0.3659, Val Acc: 0.9231\n",
      "Task: T15, Epoch: 023, Train Loss: 0.5802, Val Loss: 0.3476, Val Acc: 0.9615\n",
      "Task: T15, Epoch: 024, Train Loss: 0.5657, Val Loss: 0.4002, Val Acc: 0.8462\n",
      "Task: T15, Epoch: 025, Train Loss: 0.5592, Val Loss: 0.3459, Val Acc: 0.9231\n",
      "Early stopping at epoch 25 for task T15\n",
      "\n",
      "Training model for Task T16\n",
      "Task: T16, Epoch: 001, Train Loss: 0.6885, Val Loss: 0.6384, Val Acc: 0.6923\n",
      "Task: T16, Epoch: 002, Train Loss: 0.6797, Val Loss: 0.6222, Val Acc: 0.6923\n",
      "Task: T16, Epoch: 003, Train Loss: 0.6629, Val Loss: 0.6922, Val Acc: 0.5385\n",
      "Task: T16, Epoch: 004, Train Loss: 0.6528, Val Loss: 0.6113, Val Acc: 0.7308\n",
      "Task: T16, Epoch: 005, Train Loss: 0.6494, Val Loss: 0.6000, Val Acc: 0.7308\n",
      "Task: T16, Epoch: 006, Train Loss: 0.6289, Val Loss: 0.6331, Val Acc: 0.6538\n",
      "Task: T16, Epoch: 007, Train Loss: 0.6260, Val Loss: 0.6213, Val Acc: 0.6538\n",
      "Task: T16, Epoch: 008, Train Loss: 0.6123, Val Loss: 0.6059, Val Acc: 0.6538\n",
      "Task: T16, Epoch: 009, Train Loss: 0.5995, Val Loss: 0.5544, Val Acc: 0.6538\n",
      "Task: T16, Epoch: 010, Train Loss: 0.6053, Val Loss: 0.6045, Val Acc: 0.6538\n",
      "Task: T16, Epoch: 011, Train Loss: 0.6013, Val Loss: 0.5710, Val Acc: 0.6538\n",
      "Task: T16, Epoch: 012, Train Loss: 0.5802, Val Loss: 0.6622, Val Acc: 0.6923\n",
      "Task: T16, Epoch: 013, Train Loss: 0.5951, Val Loss: 0.5991, Val Acc: 0.6538\n",
      "Task: T16, Epoch: 014, Train Loss: 0.5675, Val Loss: 0.5595, Val Acc: 0.7308\n",
      "Early stopping at epoch 14 for task T16\n",
      "\n",
      "Training model for Task T17\n",
      "Task: T17, Epoch: 001, Train Loss: 0.7047, Val Loss: 0.7260, Val Acc: 0.3462\n",
      "Task: T17, Epoch: 002, Train Loss: 0.6856, Val Loss: 0.6966, Val Acc: 0.6154\n",
      "Task: T17, Epoch: 003, Train Loss: 0.6790, Val Loss: 0.6566, Val Acc: 0.6538\n",
      "Task: T17, Epoch: 004, Train Loss: 0.6650, Val Loss: 0.6618, Val Acc: 0.6154\n",
      "Task: T17, Epoch: 005, Train Loss: 0.6625, Val Loss: 0.6805, Val Acc: 0.6154\n",
      "Task: T17, Epoch: 006, Train Loss: 0.6683, Val Loss: 0.7039, Val Acc: 0.6154\n",
      "Task: T17, Epoch: 007, Train Loss: 0.6505, Val Loss: 0.6430, Val Acc: 0.6154\n",
      "Task: T17, Epoch: 008, Train Loss: 0.6614, Val Loss: 0.6368, Val Acc: 0.6154\n",
      "Task: T17, Epoch: 009, Train Loss: 0.6607, Val Loss: 0.6610, Val Acc: 0.6154\n",
      "Task: T17, Epoch: 010, Train Loss: 0.6503, Val Loss: 0.6668, Val Acc: 0.6154\n",
      "Task: T17, Epoch: 011, Train Loss: 0.6450, Val Loss: 0.6523, Val Acc: 0.5769\n",
      "Task: T17, Epoch: 012, Train Loss: 0.6498, Val Loss: 0.6518, Val Acc: 0.5769\n",
      "Task: T17, Epoch: 013, Train Loss: 0.6501, Val Loss: 0.6723, Val Acc: 0.6154\n",
      "Early stopping at epoch 13 for task T17\n",
      "\n",
      "Training model for Task T18\n",
      "Task: T18, Epoch: 001, Train Loss: 0.6826, Val Loss: 0.6869, Val Acc: 0.6538\n",
      "Task: T18, Epoch: 002, Train Loss: 0.6735, Val Loss: 0.6539, Val Acc: 0.6154\n",
      "Task: T18, Epoch: 003, Train Loss: 0.6507, Val Loss: 0.6522, Val Acc: 0.6538\n",
      "Task: T18, Epoch: 004, Train Loss: 0.6320, Val Loss: 0.6257, Val Acc: 0.6538\n",
      "Task: T18, Epoch: 005, Train Loss: 0.6261, Val Loss: 0.6241, Val Acc: 0.6154\n",
      "Task: T18, Epoch: 006, Train Loss: 0.6348, Val Loss: 0.6683, Val Acc: 0.6154\n",
      "Task: T18, Epoch: 007, Train Loss: 0.6026, Val Loss: 0.6424, Val Acc: 0.6154\n",
      "Task: T18, Epoch: 008, Train Loss: 0.6098, Val Loss: 0.6646, Val Acc: 0.6154\n",
      "Task: T18, Epoch: 009, Train Loss: 0.6735, Val Loss: 0.6340, Val Acc: 0.6154\n",
      "Task: T18, Epoch: 010, Train Loss: 0.6205, Val Loss: 0.7132, Val Acc: 0.4615\n",
      "Early stopping at epoch 10 for task T18\n",
      "\n",
      "Training model for Task T19\n",
      "Task: T19, Epoch: 001, Train Loss: 0.6462, Val Loss: 0.7062, Val Acc: 0.4762\n",
      "Task: T19, Epoch: 002, Train Loss: 0.8408, Val Loss: 0.6722, Val Acc: 0.5714\n",
      "Task: T19, Epoch: 003, Train Loss: 0.6804, Val Loss: 0.6751, Val Acc: 0.6667\n",
      "Task: T19, Epoch: 004, Train Loss: 0.6852, Val Loss: 0.6792, Val Acc: 0.5238\n",
      "Task: T19, Epoch: 005, Train Loss: 0.6698, Val Loss: 0.6806, Val Acc: 0.5238\n",
      "Task: T19, Epoch: 006, Train Loss: 0.6556, Val Loss: 0.6804, Val Acc: 0.5238\n",
      "Task: T19, Epoch: 007, Train Loss: 0.7815, Val Loss: 0.6789, Val Acc: 0.5238\n",
      "Early stopping at epoch 7 for task T19\n",
      "\n",
      "Training model for Task T20\n",
      "Task: T20, Epoch: 001, Train Loss: 0.6942, Val Loss: 0.6751, Val Acc: 0.6400\n",
      "Task: T20, Epoch: 002, Train Loss: 0.6668, Val Loss: 0.6431, Val Acc: 0.7200\n",
      "Task: T20, Epoch: 003, Train Loss: 0.6361, Val Loss: 0.6260, Val Acc: 0.6800\n",
      "Task: T20, Epoch: 004, Train Loss: 0.6083, Val Loss: 0.6304, Val Acc: 0.6400\n",
      "Task: T20, Epoch: 005, Train Loss: 0.5964, Val Loss: 0.6885, Val Acc: 0.6400\n",
      "Task: T20, Epoch: 006, Train Loss: 0.6186, Val Loss: 0.6521, Val Acc: 0.6400\n",
      "Task: T20, Epoch: 007, Train Loss: 0.5490, Val Loss: 0.6978, Val Acc: 0.5200\n",
      "Task: T20, Epoch: 008, Train Loss: 0.5505, Val Loss: 0.6795, Val Acc: 0.6000\n",
      "Early stopping at epoch 8 for task T20\n",
      "\n",
      "Training model for Task T21\n",
      "Task: T21, Epoch: 001, Train Loss: 0.6568, Val Loss: 0.6953, Val Acc: 0.6000\n",
      "Task: T21, Epoch: 002, Train Loss: 0.5860, Val Loss: 0.8814, Val Acc: 0.6000\n",
      "Task: T21, Epoch: 003, Train Loss: 0.6115, Val Loss: 0.7123, Val Acc: 0.6000\n",
      "Task: T21, Epoch: 004, Train Loss: 0.6076, Val Loss: 0.6383, Val Acc: 0.5600\n",
      "Task: T21, Epoch: 005, Train Loss: 0.5862, Val Loss: 0.7126, Val Acc: 0.6000\n",
      "Task: T21, Epoch: 006, Train Loss: 0.5881, Val Loss: 0.7505, Val Acc: 0.6000\n",
      "Task: T21, Epoch: 007, Train Loss: 0.6283, Val Loss: 0.7705, Val Acc: 0.6000\n",
      "Task: T21, Epoch: 008, Train Loss: 0.5800, Val Loss: 0.6737, Val Acc: 0.6000\n",
      "Task: T21, Epoch: 009, Train Loss: 0.5823, Val Loss: 0.6764, Val Acc: 0.6000\n",
      "Early stopping at epoch 9 for task T21\n",
      "\n",
      "Training model for Task T22\n",
      "Task: T22, Epoch: 001, Train Loss: 0.7196, Val Loss: 0.6900, Val Acc: 0.5200\n",
      "Task: T22, Epoch: 002, Train Loss: 0.6888, Val Loss: 0.6864, Val Acc: 0.6000\n",
      "Task: T22, Epoch: 003, Train Loss: 0.6794, Val Loss: 0.6793, Val Acc: 0.6000\n",
      "Task: T22, Epoch: 004, Train Loss: 0.6814, Val Loss: 0.6708, Val Acc: 0.6000\n",
      "Task: T22, Epoch: 005, Train Loss: 0.6719, Val Loss: 0.6752, Val Acc: 0.6000\n",
      "Task: T22, Epoch: 006, Train Loss: 0.6537, Val Loss: 0.6657, Val Acc: 0.5600\n",
      "Task: T22, Epoch: 007, Train Loss: 0.6521, Val Loss: 0.6632, Val Acc: 0.6800\n",
      "Task: T22, Epoch: 008, Train Loss: 0.6666, Val Loss: 0.6530, Val Acc: 0.6000\n",
      "Task: T22, Epoch: 009, Train Loss: 0.6397, Val Loss: 0.6650, Val Acc: 0.6800\n",
      "Task: T22, Epoch: 010, Train Loss: 0.6509, Val Loss: 0.6471, Val Acc: 0.6000\n",
      "Task: T22, Epoch: 011, Train Loss: 0.6269, Val Loss: 0.6642, Val Acc: 0.6000\n",
      "Task: T22, Epoch: 012, Train Loss: 0.6524, Val Loss: 0.6431, Val Acc: 0.5600\n",
      "Task: T22, Epoch: 013, Train Loss: 0.6410, Val Loss: 0.6341, Val Acc: 0.6000\n",
      "Task: T22, Epoch: 014, Train Loss: 0.6491, Val Loss: 0.6507, Val Acc: 0.6000\n",
      "Task: T22, Epoch: 015, Train Loss: 0.6264, Val Loss: 0.6281, Val Acc: 0.6000\n",
      "Task: T22, Epoch: 016, Train Loss: 0.6467, Val Loss: 0.6412, Val Acc: 0.6800\n",
      "Task: T22, Epoch: 017, Train Loss: 0.6294, Val Loss: 0.6276, Val Acc: 0.6800\n",
      "Task: T22, Epoch: 018, Train Loss: 0.6293, Val Loss: 0.6499, Val Acc: 0.6000\n",
      "Task: T22, Epoch: 019, Train Loss: 0.6298, Val Loss: 0.6179, Val Acc: 0.6800\n",
      "Task: T22, Epoch: 020, Train Loss: 0.6304, Val Loss: 0.6147, Val Acc: 0.6400\n",
      "Task: T22, Epoch: 021, Train Loss: 0.6192, Val Loss: 0.6147, Val Acc: 0.6400\n",
      "Task: T22, Epoch: 022, Train Loss: 0.6571, Val Loss: 0.6253, Val Acc: 0.6400\n",
      "Task: T22, Epoch: 023, Train Loss: 0.5974, Val Loss: 0.6318, Val Acc: 0.6800\n",
      "Task: T22, Epoch: 024, Train Loss: 0.6421, Val Loss: 0.6316, Val Acc: 0.6800\n",
      "Task: T22, Epoch: 025, Train Loss: 0.6033, Val Loss: 0.6350, Val Acc: 0.6000\n",
      "Task: T22, Epoch: 026, Train Loss: 0.6205, Val Loss: 0.6361, Val Acc: 0.6000\n",
      "Early stopping at epoch 26 for task T22\n",
      "\n",
      "Training model for Task T23\n",
      "Task: T23, Epoch: 001, Train Loss: 0.6848, Val Loss: 0.7237, Val Acc: 0.4000\n",
      "Task: T23, Epoch: 002, Train Loss: 0.6435, Val Loss: 0.8052, Val Acc: 0.4000\n",
      "Task: T23, Epoch: 003, Train Loss: 0.6124, Val Loss: 0.8975, Val Acc: 0.3600\n",
      "Task: T23, Epoch: 004, Train Loss: 0.6239, Val Loss: 0.8333, Val Acc: 0.4400\n",
      "Task: T23, Epoch: 005, Train Loss: 0.6087, Val Loss: 0.8097, Val Acc: 0.5200\n",
      "Task: T23, Epoch: 006, Train Loss: 0.5983, Val Loss: 0.8618, Val Acc: 0.4800\n",
      "Early stopping at epoch 6 for task T23\n",
      "\n",
      "Training model for Task T24\n",
      "Task: T24, Epoch: 001, Train Loss: 0.6882, Val Loss: 0.6187, Val Acc: 0.6800\n",
      "Task: T24, Epoch: 002, Train Loss: 0.6734, Val Loss: 0.5882, Val Acc: 0.6800\n",
      "Task: T24, Epoch: 003, Train Loss: 0.6574, Val Loss: 0.6037, Val Acc: 0.6400\n",
      "Task: T24, Epoch: 004, Train Loss: 0.6647, Val Loss: 0.6083, Val Acc: 0.6800\n",
      "Task: T24, Epoch: 005, Train Loss: 0.6742, Val Loss: 0.5800, Val Acc: 0.6800\n",
      "Task: T24, Epoch: 006, Train Loss: 0.6739, Val Loss: 0.5613, Val Acc: 0.8400\n",
      "Task: T24, Epoch: 007, Train Loss: 0.6575, Val Loss: 0.6162, Val Acc: 0.6800\n",
      "Task: T24, Epoch: 008, Train Loss: 0.6968, Val Loss: 0.6354, Val Acc: 0.6400\n",
      "Task: T24, Epoch: 009, Train Loss: 0.6537, Val Loss: 0.5980, Val Acc: 0.6800\n",
      "Task: T24, Epoch: 010, Train Loss: 0.6719, Val Loss: 0.5807, Val Acc: 0.8400\n",
      "Task: T24, Epoch: 011, Train Loss: 0.6638, Val Loss: 0.5939, Val Acc: 0.6800\n",
      "Early stopping at epoch 11 for task T24\n",
      "\n",
      "Training model for Task T25\n",
      "Task: T25, Epoch: 001, Train Loss: 0.6808, Val Loss: 0.6896, Val Acc: 0.5600\n",
      "Task: T25, Epoch: 002, Train Loss: 0.6488, Val Loss: 0.7188, Val Acc: 0.5200\n",
      "Task: T25, Epoch: 003, Train Loss: 0.6231, Val Loss: 0.7116, Val Acc: 0.5600\n",
      "Task: T25, Epoch: 004, Train Loss: 0.6490, Val Loss: 0.6861, Val Acc: 0.6000\n",
      "Task: T25, Epoch: 005, Train Loss: 0.6331, Val Loss: 0.6749, Val Acc: 0.6000\n",
      "Task: T25, Epoch: 006, Train Loss: 0.6408, Val Loss: 0.6622, Val Acc: 0.6000\n",
      "Task: T25, Epoch: 007, Train Loss: 0.6338, Val Loss: 0.6525, Val Acc: 0.6400\n",
      "Task: T25, Epoch: 008, Train Loss: 0.6252, Val Loss: 0.6815, Val Acc: 0.5200\n",
      "Task: T25, Epoch: 009, Train Loss: 0.6441, Val Loss: 0.6621, Val Acc: 0.6000\n",
      "Task: T25, Epoch: 010, Train Loss: 0.6190, Val Loss: 0.6533, Val Acc: 0.6400\n",
      "Task: T25, Epoch: 011, Train Loss: 0.6387, Val Loss: 0.6551, Val Acc: 0.6400\n",
      "Task: T25, Epoch: 012, Train Loss: 0.6380, Val Loss: 0.6617, Val Acc: 0.6000\n",
      "Early stopping at epoch 12 for task T25\n",
      "\n",
      "Training model for Task T1\n",
      "Task: T1, Epoch: 001, Train Loss: 0.6834, Val Loss: 0.7148, Val Acc: 0.4231\n",
      "Task: T1, Epoch: 002, Train Loss: 0.6783, Val Loss: 0.7250, Val Acc: 0.5000\n",
      "Task: T1, Epoch: 003, Train Loss: 0.6710, Val Loss: 0.6968, Val Acc: 0.5000\n",
      "Task: T1, Epoch: 004, Train Loss: 0.6587, Val Loss: 0.7187, Val Acc: 0.4615\n",
      "Task: T1, Epoch: 005, Train Loss: 0.6684, Val Loss: 0.7234, Val Acc: 0.4231\n",
      "Task: T1, Epoch: 006, Train Loss: 0.6534, Val Loss: 0.6770, Val Acc: 0.5769\n",
      "Task: T1, Epoch: 007, Train Loss: 0.6631, Val Loss: 0.6941, Val Acc: 0.5385\n",
      "Task: T1, Epoch: 008, Train Loss: 0.6462, Val Loss: 0.7266, Val Acc: 0.5000\n",
      "Task: T1, Epoch: 009, Train Loss: 0.6550, Val Loss: 0.7260, Val Acc: 0.4615\n",
      "Task: T1, Epoch: 010, Train Loss: 0.6474, Val Loss: 0.6800, Val Acc: 0.6154\n",
      "Task: T1, Epoch: 011, Train Loss: 0.6522, Val Loss: 0.6781, Val Acc: 0.5385\n",
      "Early stopping at epoch 11 for task T1\n",
      "\n",
      "Training model for Task T2\n",
      "Task: T2, Epoch: 001, Train Loss: 0.6819, Val Loss: 0.6430, Val Acc: 0.5769\n",
      "Task: T2, Epoch: 002, Train Loss: 0.6610, Val Loss: 0.6373, Val Acc: 0.6154\n",
      "Task: T2, Epoch: 003, Train Loss: 0.6519, Val Loss: 0.6335, Val Acc: 0.5769\n",
      "Task: T2, Epoch: 004, Train Loss: 0.6458, Val Loss: 0.6332, Val Acc: 0.6154\n",
      "Task: T2, Epoch: 005, Train Loss: 0.6365, Val Loss: 0.6293, Val Acc: 0.5385\n",
      "Task: T2, Epoch: 006, Train Loss: 0.6366, Val Loss: 0.6267, Val Acc: 0.5769\n",
      "Task: T2, Epoch: 007, Train Loss: 0.6339, Val Loss: 0.6264, Val Acc: 0.6154\n",
      "Task: T2, Epoch: 008, Train Loss: 0.6486, Val Loss: 0.6253, Val Acc: 0.5769\n",
      "Task: T2, Epoch: 009, Train Loss: 0.6467, Val Loss: 0.6217, Val Acc: 0.5385\n",
      "Task: T2, Epoch: 010, Train Loss: 0.6260, Val Loss: 0.6446, Val Acc: 0.6154\n",
      "Task: T2, Epoch: 011, Train Loss: 0.6729, Val Loss: 0.6565, Val Acc: 0.6154\n",
      "Task: T2, Epoch: 012, Train Loss: 0.6420, Val Loss: 0.6274, Val Acc: 0.5000\n",
      "Task: T2, Epoch: 013, Train Loss: 0.6379, Val Loss: 0.6246, Val Acc: 0.5000\n",
      "Task: T2, Epoch: 014, Train Loss: 0.6381, Val Loss: 0.6254, Val Acc: 0.5769\n",
      "Early stopping at epoch 14 for task T2\n",
      "\n",
      "Training model for Task T3\n",
      "Task: T3, Epoch: 001, Train Loss: 0.6867, Val Loss: 0.7365, Val Acc: 0.4231\n",
      "Task: T3, Epoch: 002, Train Loss: 0.6632, Val Loss: 0.7432, Val Acc: 0.4231\n",
      "Task: T3, Epoch: 003, Train Loss: 0.6632, Val Loss: 0.7575, Val Acc: 0.4231\n",
      "Task: T3, Epoch: 004, Train Loss: 0.6647, Val Loss: 0.7271, Val Acc: 0.5385\n",
      "Task: T3, Epoch: 005, Train Loss: 0.6577, Val Loss: 0.7226, Val Acc: 0.5000\n",
      "Task: T3, Epoch: 006, Train Loss: 0.6530, Val Loss: 0.7353, Val Acc: 0.5000\n",
      "Task: T3, Epoch: 007, Train Loss: 0.6590, Val Loss: 0.7639, Val Acc: 0.5000\n",
      "Task: T3, Epoch: 008, Train Loss: 0.6529, Val Loss: 0.7240, Val Acc: 0.5385\n",
      "Task: T3, Epoch: 009, Train Loss: 0.6509, Val Loss: 0.7256, Val Acc: 0.5385\n",
      "Task: T3, Epoch: 010, Train Loss: 0.6575, Val Loss: 0.7345, Val Acc: 0.5385\n",
      "Early stopping at epoch 10 for task T3\n",
      "\n",
      "Training model for Task T4\n",
      "Task: T4, Epoch: 001, Train Loss: 0.6769, Val Loss: 0.5813, Val Acc: 0.6923\n",
      "Task: T4, Epoch: 002, Train Loss: 0.6442, Val Loss: 0.5125, Val Acc: 0.6923\n",
      "Task: T4, Epoch: 003, Train Loss: 0.6233, Val Loss: 0.5416, Val Acc: 0.6923\n",
      "Task: T4, Epoch: 004, Train Loss: 0.6454, Val Loss: 0.5603, Val Acc: 0.6538\n",
      "Task: T4, Epoch: 005, Train Loss: 0.6235, Val Loss: 0.5155, Val Acc: 0.7692\n",
      "Task: T4, Epoch: 006, Train Loss: 0.6331, Val Loss: 0.5044, Val Acc: 0.7308\n",
      "Task: T4, Epoch: 007, Train Loss: 0.6320, Val Loss: 0.5254, Val Acc: 0.7692\n",
      "Task: T4, Epoch: 008, Train Loss: 0.6265, Val Loss: 0.5671, Val Acc: 0.6538\n",
      "Task: T4, Epoch: 009, Train Loss: 0.6268, Val Loss: 0.5505, Val Acc: 0.6923\n",
      "Task: T4, Epoch: 010, Train Loss: 0.6306, Val Loss: 0.5186, Val Acc: 0.7692\n",
      "Task: T4, Epoch: 011, Train Loss: 0.6190, Val Loss: 0.5214, Val Acc: 0.7692\n",
      "Early stopping at epoch 11 for task T4\n",
      "\n",
      "Training model for Task T10\n",
      "Task: T10, Epoch: 001, Train Loss: 0.6805, Val Loss: 0.6682, Val Acc: 0.6154\n",
      "Task: T10, Epoch: 002, Train Loss: 0.6459, Val Loss: 0.6610, Val Acc: 0.6154\n",
      "Task: T10, Epoch: 003, Train Loss: 0.6298, Val Loss: 0.6712, Val Acc: 0.6538\n",
      "Task: T10, Epoch: 004, Train Loss: 0.6255, Val Loss: 0.6432, Val Acc: 0.6538\n",
      "Task: T10, Epoch: 005, Train Loss: 0.6179, Val Loss: 0.6579, Val Acc: 0.6154\n",
      "Task: T10, Epoch: 006, Train Loss: 0.6201, Val Loss: 0.6740, Val Acc: 0.5385\n",
      "Task: T10, Epoch: 007, Train Loss: 0.6124, Val Loss: 0.6733, Val Acc: 0.5769\n",
      "Task: T10, Epoch: 008, Train Loss: 0.6205, Val Loss: 0.6956, Val Acc: 0.5385\n",
      "Task: T10, Epoch: 009, Train Loss: 0.5913, Val Loss: 0.6372, Val Acc: 0.5385\n",
      "Task: T10, Epoch: 010, Train Loss: 0.6074, Val Loss: 0.7194, Val Acc: 0.5385\n",
      "Task: T10, Epoch: 011, Train Loss: 0.6286, Val Loss: 0.7002, Val Acc: 0.5000\n",
      "Task: T10, Epoch: 012, Train Loss: 0.5964, Val Loss: 0.6219, Val Acc: 0.7308\n",
      "Task: T10, Epoch: 013, Train Loss: 0.6215, Val Loss: 0.6912, Val Acc: 0.5769\n",
      "Task: T10, Epoch: 014, Train Loss: 0.5864, Val Loss: 0.6928, Val Acc: 0.5769\n",
      "Task: T10, Epoch: 015, Train Loss: 0.5864, Val Loss: 0.6607, Val Acc: 0.5769\n",
      "Task: T10, Epoch: 016, Train Loss: 0.5746, Val Loss: 0.6587, Val Acc: 0.5000\n",
      "Task: T10, Epoch: 017, Train Loss: 0.5708, Val Loss: 0.6836, Val Acc: 0.4615\n",
      "Early stopping at epoch 17 for task T10\n",
      "\n",
      "Training model for Task T11\n",
      "Task: T11, Epoch: 001, Train Loss: 0.6907, Val Loss: 0.6849, Val Acc: 0.5385\n",
      "Task: T11, Epoch: 002, Train Loss: 0.6668, Val Loss: 0.6520, Val Acc: 0.6154\n",
      "Task: T11, Epoch: 003, Train Loss: 0.6888, Val Loss: 0.6047, Val Acc: 0.6538\n",
      "Task: T11, Epoch: 004, Train Loss: 0.6464, Val Loss: 0.6879, Val Acc: 0.5385\n",
      "Task: T11, Epoch: 005, Train Loss: 0.6425, Val Loss: 0.6955, Val Acc: 0.5385\n",
      "Task: T11, Epoch: 006, Train Loss: 0.6387, Val Loss: 0.6469, Val Acc: 0.5385\n",
      "Task: T11, Epoch: 007, Train Loss: 0.6211, Val Loss: 0.6294, Val Acc: 0.6154\n",
      "Task: T11, Epoch: 008, Train Loss: 0.6178, Val Loss: 0.6414, Val Acc: 0.5385\n",
      "Early stopping at epoch 8 for task T11\n",
      "\n",
      "Training model for Task T12\n",
      "Task: T12, Epoch: 001, Train Loss: 0.6835, Val Loss: 0.6900, Val Acc: 0.4615\n",
      "Task: T12, Epoch: 002, Train Loss: 0.6661, Val Loss: 0.7099, Val Acc: 0.4615\n",
      "Task: T12, Epoch: 003, Train Loss: 0.6546, Val Loss: 0.7023, Val Acc: 0.5385\n",
      "Task: T12, Epoch: 004, Train Loss: 0.6593, Val Loss: 0.6785, Val Acc: 0.6538\n",
      "Task: T12, Epoch: 005, Train Loss: 0.6330, Val Loss: 0.6787, Val Acc: 0.5000\n",
      "Task: T12, Epoch: 006, Train Loss: 0.6343, Val Loss: 0.7129, Val Acc: 0.5769\n",
      "Task: T12, Epoch: 007, Train Loss: 0.6356, Val Loss: 0.6791, Val Acc: 0.5385\n",
      "Task: T12, Epoch: 008, Train Loss: 0.6334, Val Loss: 0.6590, Val Acc: 0.6923\n",
      "Task: T12, Epoch: 009, Train Loss: 0.6113, Val Loss: 0.6591, Val Acc: 0.6538\n",
      "Task: T12, Epoch: 010, Train Loss: 0.6335, Val Loss: 0.6552, Val Acc: 0.6538\n",
      "Task: T12, Epoch: 011, Train Loss: 0.6073, Val Loss: 0.6528, Val Acc: 0.6923\n",
      "Task: T12, Epoch: 012, Train Loss: 0.6106, Val Loss: 0.6478, Val Acc: 0.5769\n",
      "Task: T12, Epoch: 013, Train Loss: 0.6135, Val Loss: 0.6342, Val Acc: 0.6923\n",
      "Task: T12, Epoch: 014, Train Loss: 0.5998, Val Loss: 0.6045, Val Acc: 0.6538\n",
      "Task: T12, Epoch: 015, Train Loss: 0.6109, Val Loss: 0.6546, Val Acc: 0.6538\n",
      "Task: T12, Epoch: 016, Train Loss: 0.6061, Val Loss: 0.6206, Val Acc: 0.6538\n",
      "Task: T12, Epoch: 017, Train Loss: 0.5813, Val Loss: 0.6172, Val Acc: 0.6923\n",
      "Task: T12, Epoch: 018, Train Loss: 0.5901, Val Loss: 0.5960, Val Acc: 0.7308\n",
      "Task: T12, Epoch: 019, Train Loss: 0.6064, Val Loss: 0.6236, Val Acc: 0.6538\n",
      "Task: T12, Epoch: 020, Train Loss: 0.5982, Val Loss: 0.6278, Val Acc: 0.6538\n",
      "Task: T12, Epoch: 021, Train Loss: 0.5687, Val Loss: 0.5607, Val Acc: 0.7308\n",
      "Task: T12, Epoch: 022, Train Loss: 0.5833, Val Loss: 0.5900, Val Acc: 0.7308\n",
      "Task: T12, Epoch: 023, Train Loss: 0.5792, Val Loss: 0.6528, Val Acc: 0.6923\n",
      "Task: T12, Epoch: 024, Train Loss: 0.6108, Val Loss: 0.5755, Val Acc: 0.7308\n",
      "Task: T12, Epoch: 025, Train Loss: 0.6039, Val Loss: 0.6056, Val Acc: 0.6923\n",
      "Task: T12, Epoch: 026, Train Loss: 0.5812, Val Loss: 0.5682, Val Acc: 0.6923\n",
      "Early stopping at epoch 26 for task T12\n",
      "\n",
      "Training model for Task T13\n",
      "Task: T13, Epoch: 001, Train Loss: 0.6799, Val Loss: 0.6951, Val Acc: 0.5769\n",
      "Task: T13, Epoch: 002, Train Loss: 0.6690, Val Loss: 0.6616, Val Acc: 0.5769\n",
      "Task: T13, Epoch: 003, Train Loss: 0.6530, Val Loss: 0.6609, Val Acc: 0.5385\n",
      "Task: T13, Epoch: 004, Train Loss: 0.6396, Val Loss: 0.6668, Val Acc: 0.5000\n",
      "Task: T13, Epoch: 005, Train Loss: 0.6496, Val Loss: 0.6413, Val Acc: 0.6538\n",
      "Task: T13, Epoch: 006, Train Loss: 0.6527, Val Loss: 0.6439, Val Acc: 0.5385\n",
      "Task: T13, Epoch: 007, Train Loss: 0.6067, Val Loss: 0.7634, Val Acc: 0.4231\n",
      "Task: T13, Epoch: 008, Train Loss: 0.6469, Val Loss: 0.6626, Val Acc: 0.5769\n",
      "Task: T13, Epoch: 009, Train Loss: 0.6255, Val Loss: 0.6409, Val Acc: 0.5769\n",
      "Task: T13, Epoch: 010, Train Loss: 0.6382, Val Loss: 0.6601, Val Acc: 0.6154\n",
      "Task: T13, Epoch: 011, Train Loss: 0.6311, Val Loss: 0.6422, Val Acc: 0.5769\n",
      "Task: T13, Epoch: 012, Train Loss: 0.6573, Val Loss: 0.6389, Val Acc: 0.6538\n",
      "Task: T13, Epoch: 013, Train Loss: 0.6171, Val Loss: 0.7042, Val Acc: 0.5385\n",
      "Task: T13, Epoch: 014, Train Loss: 0.6306, Val Loss: 0.6808, Val Acc: 0.6154\n",
      "Task: T13, Epoch: 015, Train Loss: 0.6200, Val Loss: 0.6501, Val Acc: 0.6538\n",
      "Task: T13, Epoch: 016, Train Loss: 0.6182, Val Loss: 0.6567, Val Acc: 0.6154\n",
      "Task: T13, Epoch: 017, Train Loss: 0.6444, Val Loss: 0.7094, Val Acc: 0.5385\n",
      "Early stopping at epoch 17 for task T13\n",
      "\n",
      "Training model for Task T14\n",
      "Task: T14, Epoch: 001, Train Loss: 0.6865, Val Loss: 0.6631, Val Acc: 0.8000\n",
      "Task: T14, Epoch: 002, Train Loss: 0.6615, Val Loss: 0.6238, Val Acc: 0.7200\n",
      "Task: T14, Epoch: 003, Train Loss: 0.6380, Val Loss: 0.6087, Val Acc: 0.7200\n",
      "Task: T14, Epoch: 004, Train Loss: 0.6171, Val Loss: 0.6428, Val Acc: 0.6800\n",
      "Task: T14, Epoch: 005, Train Loss: 0.6219, Val Loss: 0.6160, Val Acc: 0.6800\n",
      "Task: T14, Epoch: 006, Train Loss: 0.6206, Val Loss: 0.5849, Val Acc: 0.8000\n",
      "Task: T14, Epoch: 007, Train Loss: 0.6195, Val Loss: 0.6325, Val Acc: 0.6000\n",
      "Task: T14, Epoch: 008, Train Loss: 0.6065, Val Loss: 0.6839, Val Acc: 0.5200\n",
      "Task: T14, Epoch: 009, Train Loss: 0.5914, Val Loss: 0.6014, Val Acc: 0.7200\n",
      "Task: T14, Epoch: 010, Train Loss: 0.5957, Val Loss: 0.5753, Val Acc: 0.8000\n",
      "Task: T14, Epoch: 011, Train Loss: 0.5977, Val Loss: 0.5860, Val Acc: 0.7600\n",
      "Task: T14, Epoch: 012, Train Loss: 0.5800, Val Loss: 0.6420, Val Acc: 0.6000\n",
      "Task: T14, Epoch: 013, Train Loss: 0.5838, Val Loss: 0.6042, Val Acc: 0.6800\n",
      "Task: T14, Epoch: 014, Train Loss: 0.5871, Val Loss: 0.5819, Val Acc: 0.7200\n",
      "Task: T14, Epoch: 015, Train Loss: 0.5775, Val Loss: 0.5762, Val Acc: 0.7200\n",
      "Early stopping at epoch 15 for task T14\n",
      "\n",
      "Training model for Task T5\n",
      "Task: T5, Epoch: 001, Train Loss: 0.7089, Val Loss: 0.6781, Val Acc: 0.5769\n",
      "Task: T5, Epoch: 002, Train Loss: 0.6756, Val Loss: 0.6199, Val Acc: 0.7692\n",
      "Task: T5, Epoch: 003, Train Loss: 0.6673, Val Loss: 0.5476, Val Acc: 0.7692\n",
      "Task: T5, Epoch: 004, Train Loss: 0.6566, Val Loss: 0.5455, Val Acc: 0.6538\n",
      "Task: T5, Epoch: 005, Train Loss: 0.6425, Val Loss: 0.5607, Val Acc: 0.6538\n",
      "Task: T5, Epoch: 006, Train Loss: 0.6452, Val Loss: 0.5563, Val Acc: 0.6923\n",
      "Task: T5, Epoch: 007, Train Loss: 0.6585, Val Loss: 0.5309, Val Acc: 0.6538\n",
      "Task: T5, Epoch: 008, Train Loss: 0.6437, Val Loss: 0.5570, Val Acc: 0.6538\n",
      "Task: T5, Epoch: 009, Train Loss: 0.6509, Val Loss: 0.5826, Val Acc: 0.6923\n",
      "Task: T5, Epoch: 010, Train Loss: 0.6578, Val Loss: 0.5573, Val Acc: 0.6538\n",
      "Task: T5, Epoch: 011, Train Loss: 0.6453, Val Loss: 0.5623, Val Acc: 0.6538\n",
      "Task: T5, Epoch: 012, Train Loss: 0.6531, Val Loss: 0.5662, Val Acc: 0.6923\n",
      "Early stopping at epoch 12 for task T5\n",
      "\n",
      "Training model for Task T6\n",
      "Task: T6, Epoch: 001, Train Loss: 0.6956, Val Loss: 0.6622, Val Acc: 0.6538\n",
      "Task: T6, Epoch: 002, Train Loss: 0.6783, Val Loss: 0.6154, Val Acc: 0.6538\n",
      "Task: T6, Epoch: 003, Train Loss: 0.6631, Val Loss: 0.5753, Val Acc: 0.6923\n",
      "Task: T6, Epoch: 004, Train Loss: 0.6526, Val Loss: 0.5384, Val Acc: 0.7308\n",
      "Task: T6, Epoch: 005, Train Loss: 0.6751, Val Loss: 0.5469, Val Acc: 0.7308\n",
      "Task: T6, Epoch: 006, Train Loss: 0.6432, Val Loss: 0.5861, Val Acc: 0.7308\n",
      "Task: T6, Epoch: 007, Train Loss: 0.6424, Val Loss: 0.5348, Val Acc: 0.7308\n",
      "Task: T6, Epoch: 008, Train Loss: 0.6314, Val Loss: 0.5214, Val Acc: 0.7308\n",
      "Task: T6, Epoch: 009, Train Loss: 0.6254, Val Loss: 0.5181, Val Acc: 0.7692\n",
      "Task: T6, Epoch: 010, Train Loss: 0.6278, Val Loss: 0.5094, Val Acc: 0.7692\n",
      "Task: T6, Epoch: 011, Train Loss: 0.6127, Val Loss: 0.5021, Val Acc: 0.6923\n",
      "Task: T6, Epoch: 012, Train Loss: 0.6196, Val Loss: 0.5035, Val Acc: 0.7692\n",
      "Task: T6, Epoch: 013, Train Loss: 0.6079, Val Loss: 0.4816, Val Acc: 0.7692\n",
      "Task: T6, Epoch: 014, Train Loss: 0.6319, Val Loss: 0.4729, Val Acc: 0.8077\n",
      "Task: T6, Epoch: 015, Train Loss: 0.5927, Val Loss: 0.4827, Val Acc: 0.6923\n",
      "Task: T6, Epoch: 016, Train Loss: 0.5946, Val Loss: 0.4932, Val Acc: 0.7692\n",
      "Task: T6, Epoch: 017, Train Loss: 0.5961, Val Loss: 0.4664, Val Acc: 0.7692\n",
      "Task: T6, Epoch: 018, Train Loss: 0.6061, Val Loss: 0.4521, Val Acc: 0.8077\n",
      "Task: T6, Epoch: 019, Train Loss: 0.5973, Val Loss: 0.4926, Val Acc: 0.7692\n",
      "Task: T6, Epoch: 020, Train Loss: 0.5997, Val Loss: 0.4737, Val Acc: 0.8077\n",
      "Task: T6, Epoch: 021, Train Loss: 0.5973, Val Loss: 0.4651, Val Acc: 0.8462\n",
      "Task: T6, Epoch: 022, Train Loss: 0.6041, Val Loss: 0.4745, Val Acc: 0.8462\n",
      "Task: T6, Epoch: 023, Train Loss: 0.5826, Val Loss: 0.4624, Val Acc: 0.7692\n",
      "Early stopping at epoch 23 for task T6\n",
      "\n",
      "Training model for Task T7\n",
      "Task: T7, Epoch: 001, Train Loss: 0.6897, Val Loss: 0.7075, Val Acc: 0.4231\n",
      "Task: T7, Epoch: 002, Train Loss: 0.6547, Val Loss: 0.7335, Val Acc: 0.4231\n",
      "Task: T7, Epoch: 003, Train Loss: 0.6577, Val Loss: 0.7261, Val Acc: 0.4615\n",
      "Task: T7, Epoch: 004, Train Loss: 0.6422, Val Loss: 0.6831, Val Acc: 0.5769\n",
      "Task: T7, Epoch: 005, Train Loss: 0.6330, Val Loss: 0.6843, Val Acc: 0.5769\n",
      "Task: T7, Epoch: 006, Train Loss: 0.6246, Val Loss: 0.7041, Val Acc: 0.5769\n",
      "Task: T7, Epoch: 007, Train Loss: 0.6133, Val Loss: 0.6774, Val Acc: 0.6538\n",
      "Task: T7, Epoch: 008, Train Loss: 0.6132, Val Loss: 0.6823, Val Acc: 0.6538\n",
      "Task: T7, Epoch: 009, Train Loss: 0.6090, Val Loss: 0.6897, Val Acc: 0.6538\n",
      "Task: T7, Epoch: 010, Train Loss: 0.6054, Val Loss: 0.7318, Val Acc: 0.5385\n",
      "Task: T7, Epoch: 011, Train Loss: 0.5897, Val Loss: 0.6523, Val Acc: 0.6538\n",
      "Task: T7, Epoch: 012, Train Loss: 0.5979, Val Loss: 0.7009, Val Acc: 0.6538\n",
      "Task: T7, Epoch: 013, Train Loss: 0.5888, Val Loss: 0.7320, Val Acc: 0.6923\n",
      "Task: T7, Epoch: 014, Train Loss: 0.5939, Val Loss: 0.6502, Val Acc: 0.6538\n",
      "Task: T7, Epoch: 015, Train Loss: 0.5945, Val Loss: 0.6657, Val Acc: 0.6923\n",
      "Task: T7, Epoch: 016, Train Loss: 0.5801, Val Loss: 0.7549, Val Acc: 0.6154\n",
      "Task: T7, Epoch: 017, Train Loss: 0.5829, Val Loss: 0.6740, Val Acc: 0.6923\n",
      "Task: T7, Epoch: 018, Train Loss: 0.5797, Val Loss: 0.6733, Val Acc: 0.6923\n",
      "Task: T7, Epoch: 019, Train Loss: 0.5741, Val Loss: 0.6701, Val Acc: 0.6923\n",
      "Early stopping at epoch 19 for task T7\n",
      "\n",
      "Training model for Task T8\n",
      "Task: T8, Epoch: 001, Train Loss: 0.6909, Val Loss: 0.6439, Val Acc: 0.5769\n",
      "Task: T8, Epoch: 002, Train Loss: 0.6444, Val Loss: 0.5997, Val Acc: 0.6154\n",
      "Task: T8, Epoch: 003, Train Loss: 0.6157, Val Loss: 0.6091, Val Acc: 0.5769\n",
      "Task: T8, Epoch: 004, Train Loss: 0.5868, Val Loss: 0.6341, Val Acc: 0.6154\n",
      "Task: T8, Epoch: 005, Train Loss: 0.6034, Val Loss: 0.6695, Val Acc: 0.5769\n",
      "Task: T8, Epoch: 006, Train Loss: 0.5940, Val Loss: 0.6322, Val Acc: 0.6154\n",
      "Task: T8, Epoch: 007, Train Loss: 0.5841, Val Loss: 0.6239, Val Acc: 0.6154\n",
      "Early stopping at epoch 7 for task T8\n",
      "\n",
      "Training model for Task T9\n",
      "Task: T9, Epoch: 001, Train Loss: 0.6840, Val Loss: 0.6338, Val Acc: 0.6154\n",
      "Task: T9, Epoch: 002, Train Loss: 0.6214, Val Loss: 0.6547, Val Acc: 0.6154\n",
      "Task: T9, Epoch: 003, Train Loss: 0.6457, Val Loss: 0.6060, Val Acc: 0.6154\n",
      "Task: T9, Epoch: 004, Train Loss: 0.6346, Val Loss: 0.6641, Val Acc: 0.5385\n",
      "Task: T9, Epoch: 005, Train Loss: 0.6399, Val Loss: 0.6003, Val Acc: 0.6154\n",
      "Task: T9, Epoch: 006, Train Loss: 0.6265, Val Loss: 0.6058, Val Acc: 0.6154\n",
      "Task: T9, Epoch: 007, Train Loss: 0.6179, Val Loss: 0.6266, Val Acc: 0.5769\n",
      "Task: T9, Epoch: 008, Train Loss: 0.6106, Val Loss: 0.6202, Val Acc: 0.5769\n",
      "Task: T9, Epoch: 009, Train Loss: 0.6081, Val Loss: 0.6101, Val Acc: 0.5769\n",
      "Task: T9, Epoch: 010, Train Loss: 0.6031, Val Loss: 0.6166, Val Acc: 0.5769\n",
      "Early stopping at epoch 10 for task T9\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the GAT model (unchanged)\n",
    "class GATModel(nn.Module):\n",
    "    def __init__(self, in_channels=3, hidden_channels=16, out_channels=1, heads=4):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, edge_dim=7)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, edge_dim=7)\n",
    "        self.conv3 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, edge_dim=7)\n",
    "        self.lin = nn.Linear(hidden_channels * heads, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = F.relu(self.conv3(x, edge_index, edge_attr))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "# Training function\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        # Use squeeze(-1) to preserve batch dimension\n",
    "        loss = criterion(out.squeeze(-1), data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss = criterion(out.squeeze(), data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            pred = (out.squeeze() > 0).float()\n",
    "            correct += (pred == data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Training loop for each task\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "task_models = {}\n",
    "patience = 5\n",
    "\n",
    "for task, graphs in task_graphs.items():\n",
    "    print(f\"\\nTraining model for Task {task}\")\n",
    "    train_loader = DataLoader(graphs['train'], batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(graphs['val'], batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(graphs['test'], batch_size=32, shuffle=False)\n",
    "\n",
    "    model = GATModel().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    for epoch in range(1, 201):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        print(f\"Task: {task}, Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'best_model_{task}.pth')\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch} for task {task}\")\n",
    "                break\n",
    "\n",
    "    task_models[task] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: T15, Final Test Loss: 0.5458, Test Accuracy: 0.7308\n",
      "Task: T16, Final Test Loss: 0.5253, Test Accuracy: 0.7692\n",
      "Task: T17, Final Test Loss: 0.6035, Test Accuracy: 0.6538\n",
      "Task: T18, Final Test Loss: 0.5878, Test Accuracy: 0.7692\n",
      "Task: T19, Final Test Loss: 0.6069, Test Accuracy: 0.7619\n",
      "Task: T20, Final Test Loss: 0.6074, Test Accuracy: 0.7200\n",
      "Task: T21, Final Test Loss: 0.4576, Test Accuracy: 0.9167\n",
      "Task: T22, Final Test Loss: 0.5842, Test Accuracy: 0.7600\n",
      "Task: T23, Final Test Loss: 0.6527, Test Accuracy: 0.6000\n",
      "Task: T24, Final Test Loss: 0.6231, Test Accuracy: 0.6400\n",
      "Task: T25, Final Test Loss: 0.6161, Test Accuracy: 0.6800\n",
      "Task: T1, Final Test Loss: 0.6147, Test Accuracy: 0.6538\n",
      "Task: T2, Final Test Loss: 0.5818, Test Accuracy: 0.8077\n",
      "Task: T3, Final Test Loss: 0.6695, Test Accuracy: 0.6538\n",
      "Task: T4, Final Test Loss: 0.6005, Test Accuracy: 0.7308\n",
      "Task: T10, Final Test Loss: 0.6273, Test Accuracy: 0.5385\n",
      "Task: T11, Final Test Loss: 0.6524, Test Accuracy: 0.5769\n",
      "Task: T12, Final Test Loss: 0.5875, Test Accuracy: 0.7308\n",
      "Task: T13, Final Test Loss: 0.6254, Test Accuracy: 0.6538\n",
      "Task: T14, Final Test Loss: 0.6279, Test Accuracy: 0.7600\n",
      "Task: T5, Final Test Loss: 0.5582, Test Accuracy: 0.7692\n",
      "Task: T6, Final Test Loss: 0.7052, Test Accuracy: 0.5769\n",
      "Task: T7, Final Test Loss: 0.5990, Test Accuracy: 0.7692\n",
      "Task: T8, Final Test Loss: 0.6725, Test Accuracy: 0.5385\n",
      "Task: T9, Final Test Loss: 0.5964, Test Accuracy: 0.6923\n"
     ]
    }
   ],
   "source": [
    "for task, model in task_models.items():\n",
    "    model.load_state_dict(torch.load(f'best_model_{task}.pth'))\n",
    "    test_loader = DataLoader(task_graphs[task]['test'], batch_size=32, shuffle=False)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Task: {task}, Final Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasciencecourses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
